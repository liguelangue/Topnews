{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import collections\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from gensim import corpora, models, matutils\n",
    "\n",
    "from gensim.models import doc2vec, Doc2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingelPassCluster(object):\n",
    "\n",
    "    '''\n",
    "        利用tfidf vec计算cossim\n",
    "    '''\n",
    "    def tfidf_vec(self, corpus, pivot=10, slope=0.25):\n",
    "        dictionary = corpora.Dictionary(corpus)  # 形成词典映射\n",
    "        self.dict_size = len(dictionary)\n",
    "        print('dictionary size:{}'.format(len(dictionary)))\n",
    "        corpus = [dictionary.doc2bow(text) for text in corpus]  # 词的向量表示\n",
    "        tfidf = models.TfidfModel(corpus, pivot=pivot, slope=slope)\n",
    "        corpus_tfidf = tfidf[corpus]\n",
    "        return corpus_tfidf\n",
    "\n",
    "    def get_max_similarity(self, cluster_cores, vector):\n",
    "        max_value = 0\n",
    "        max_index = -1\n",
    "        print('vector:{}'.format(vector))\n",
    "        for k, core in cluster_cores.items():\n",
    "            print('core:{}'.format(core))\n",
    "            similarity = matutils.cossim(vector, core)\n",
    "            if similarity > max_value:\n",
    "                max_value = similarity\n",
    "                max_index = k\n",
    "        return max_index, max_value\n",
    "\n",
    "    def single_pass(self, corpus_vec, corpus, theta):\n",
    "        clusters = {}\n",
    "        cluster_cores = {}\n",
    "        cluster_text = {}\n",
    "        num_topic = 0\n",
    "        cnt = 0\n",
    "        for vector, text in zip(corpus_vec, corpus):\n",
    "            if num_topic == 0:\n",
    "                clusters.setdefault(num_topic, []).append(vector)\n",
    "                cluster_cores[num_topic] = vector\n",
    "                cluster_text.setdefault(num_topic, []).append(text)\n",
    "                num_topic += 1\n",
    "            else:\n",
    "                max_index, max_value = self.get_max_similarity(cluster_cores, vector)\n",
    "                if max_value > theta:\n",
    "                    clusters[max_index].append(vector)\n",
    "                    text_matrix = matutils.corpus2dense(clusters[max_index], num_terms=self.dict_size,\n",
    "                                                        num_docs=len(clusters[max_index])).T  # 稀疏转稠密\n",
    "                    core = np.mean(text_matrix, axis=0)  # 更新簇中心\n",
    "                    core = matutils.any2sparse(core)  # 将稠密向量core转为稀疏向量\n",
    "                    cluster_cores[max_index] = core\n",
    "                    cluster_text[max_index].append(text)\n",
    "                else:  # 创建一个新簇\n",
    "                    clusters.setdefault(num_topic, []).append(vector)\n",
    "                    cluster_cores[num_topic] = vector\n",
    "                    cluster_text.setdefault(num_topic, []).append(text)\n",
    "                    num_topic += 1\n",
    "            cnt += 1\n",
    "            if cnt % 100 == 0:\n",
    "                print('processing {}...'.format(cnt))\n",
    "        return clusters, cluster_text\n",
    "\n",
    "    def fit_transform(self, corpus, raw_data, theta=0.5):\n",
    "        tfidf_vec = self.tfidf_vec(corpus)  # tfidf_vec是稀疏向量\n",
    "        clusters, cluster_text = self.single_pass(tfidf_vec, raw_data, theta)\n",
    "        return clusters, cluster_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    process_text = './tf_idf.txt'  # 处理后的样本路径\n",
    "    cluster_result = './cluster_result.txt'\n",
    "\n",
    "    corpus = load_data(process_text)\n",
    "    raw_text = load_samples(process_text)\n",
    "\n",
    "    index2corpus = collections.OrderedDict()\n",
    "    for index, line in enumerate(raw_text):\n",
    "        index2corpus[index] = line\n",
    "    text2index = list(index2corpus.keys())\n",
    "    print('docs total size:{}'.format(len(text2index)))\n",
    "\n",
    "    single_cluster = SingelPassCluster()\n",
    "\n",
    "    clusters, cluster_text = single_cluster.fit_transform(corpus, text2index, theta=0.4)\n",
    "\n",
    "\n",
    "    print(\"............................................................................................\")\n",
    "    print(\"得到的类数量有: {} 个 ...\".format(len(clusters)))\n",
    "    print(\"............................................................................................\\n\")\n",
    "    # 按聚类语句数量对聚类结果进行降序排列\n",
    "    clusterTopic_list = sorted(cluster_text.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "    with open(cluster_result, 'w', encoding='utf-8') as file_write:\n",
    "        for k in clusterTopic_list:\n",
    "            cluster_text = []\n",
    "            for index, value in enumerate(k[1],start=1):\n",
    "                cluster_text.append('(' + str(index) + '): ' + index2corpus[value])\n",
    "            cluster_text = '\\n'.join(cluster_text)\n",
    "            file_write.write(\"【簇索引】:{} \\n【簇中文档数】：{} \\n【簇中文档】 ：\\n{}\".format(k[0], len(k[1]), cluster_text))\n",
    "            file_write.write('\\n')\n",
    "            file_write.flush()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f95fa36c7e4c51eacc47621d6b5b12b95b1240208d9d0223f73170116e5fb93b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
